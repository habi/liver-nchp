{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle and check the 'data' of the all the scans we did\n",
    "Wrestle with the data, check parameters and generate some helping files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import os\n",
    "import glob\n",
    "import pandas\n",
    "import imageio\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "import seaborn\n",
    "import dask\n",
    "import dask_image.imread\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from numcodecs import Blosc\n",
    "import skimage\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask temporarry files go to /media/habi/Fast_SSD/tmp\n"
     ]
    }
   ],
   "source": [
    "# Set dask temporary folder\n",
    "# Do this before creating a client: https://stackoverflow.com/a/62804525/323100\n",
    "import tempfile\n",
    "if 'Linux' in platform.system():\n",
    "    tmp = os.path.join(os.sep, 'media', 'habi', 'Fast_SSD')\n",
    "elif 'Darwin' in platform.system():\n",
    "    tmp = tempfile.gettempdir()\n",
    "else:\n",
    "    if 'anaklin' in platform.node():\n",
    "        tmp = os.path.join('F:\\\\')\n",
    "    else:\n",
    "        tmp = os.path.join('D:\\\\')\n",
    "dask.config.set({'temporary_directory': os.path.join(tmp, 'tmp')})\n",
    "print('Dask temporarry files go to %s' % dask.config.get('temporary_directory'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habi/miniconda3/lib/python3.9/site-packages/distributed/node.py:181: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 38679 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Start cluster and client now, after setting tempdir\n",
    "cluster = LocalCluster(n_workers=8)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can seee what DASK is doing at \"http://localhost:38679/status\"\n"
     ]
    }
   ],
   "source": [
    "print('You can seee what DASK is doing at \"http://localhost:%s/status\"' % client.scheduler_info()['services']['dashboard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ignore warnings in the notebook\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure defaults\n",
    "plt.rc('image', cmap='gray', interpolation='nearest')  # Display all images in b&w and with 'nearest' interpolation\n",
    "plt.rcParams['figure.figsize'] = (16, 9)  # Size up figures a bit\n",
    "plt.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup scale bar defaults\n",
    "plt.rcParams['scalebar.location'] = 'lower right'\n",
    "plt.rcParams['scalebar.frameon'] = False\n",
    "plt.rcParams['scalebar.color'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all plots identically\n",
    "lines = 3\n",
    "# And then do something like\n",
    "# plt.subplot(lines, numpy.ceil(len(Data) / float(lines)), c + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are loading all the data from /home/habi/P/Documents/Semela-Liver/Data/Liver-Semela\n"
     ]
    }
   ],
   "source": [
    "# Different locations if running either on Linux or Windows\n",
    "Archive = False # Load the data directly from the iee-research_storage drive\n",
    "# to speed things up significantly\n",
    "if Archive:\n",
    "    if 'Linux' in platform.system():\n",
    "        BasePath = os.path.join(os.sep, 'home', 'habi', 'research-storage-uct', 'Archiv_Tape')\n",
    "    elif 'Windows' in platform.system():\n",
    "        BasePath = os.path.join('R:\\\\Archiv_Tape')\n",
    "else:\n",
    "    BasePath = os.path.join(os.getcwd(), 'Data')\n",
    "Root = os.path.join(BasePath, 'Liver-Semela')\n",
    "print('We are loading all the data from %s' % Root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixelsize(logfile):\n",
    "    \"\"\"Get the pixel size from the scan log file\"\"\"\n",
    "    pixelsize=None    \n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Image Pixel' in line and 'Scaled' not in line:\n",
    "                pixelsize = float(line.split('=')[1])\n",
    "    return(pixelsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_operator(logfile):\n",
    "    \"\"\"Get the operator who scanned the samples\"\"\"\n",
    "    operator = None\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'User Name' in line:\n",
    "                operator = line.split('=')[1].strip()\n",
    "    return(operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiment(i):\n",
    "    '''Categorize  into 'Notch' or 'Control' '''\n",
    "    if 'notch' in i:\n",
    "        return 'Notch'\n",
    "    if 'ctrl' in i:\n",
    "        return 'Control'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vein(i):\n",
    "    if 'portal' in i:\n",
    "        return 'Portal'\n",
    "    elif 'cava' in i:\n",
    "        return 'Cava'\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_git_hash():\n",
    "    '''\n",
    "    Get the current git hash from the repository.\n",
    "    Based on http://stackoverflow.com/a/949391/323100 and\n",
    "    http://stackoverflow.com/a/18283905/323100\n",
    "    '''\n",
    "    from subprocess import Popen, PIPE\n",
    "    import os\n",
    "    gitprocess = Popen(['git',\n",
    "                        '--git-dir',\n",
    "                        os.path.join(os.getcwd(), '.git'),\n",
    "                        'rev-parse',\n",
    "                        '--short',\n",
    "                        '--verify',\n",
    "                        'HEAD'],\n",
    "                       stdout=PIPE)\n",
    "    (output, _) = gitprocess.communicate()\n",
    "    return output.strip().decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make directory for output\n",
    "# OutPutDir = os.path.join(os.getcwd(), 'Output', get_git_hash())\n",
    "# print('We are saving all the output to %s' % OutPutDir)\n",
    "# os.makedirs(OutPutDir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mario Novkovic told us that \n",
    "> We have used the ds17 livers in the paper, specifically ctrl4 and notch1_2 in the first batch (training dataset), while the second batch consisted of 3 datasets from each mouse type: ctrl1, ctrl2, ctrl5 and notch1_1, notch1_3, notch1_4.\n",
    "\n",
    "So let's only use *those* folders for the remainder of the notebook.\n",
    "We copied all the relevant data from the archive to the `Data`-subfolder here with\n",
    "````bash\n",
    "rsync --verbose --recursive --times --update --omit-dir-times --include=\"*/\" --include=\"*.?og\" --include=\"*.c?v\" --include=\"*.?oi\" --include=\"*.?at\" --include=\"*_spr*.bmp\" --include=\"*.txt\" --include=\"*.md\" --include=\"*.mp\" --include=\"*.sb\" --include=\"*.info\" --include=\"*.?nc\" --include=\"*.bkp\" --exclude=\"*\" ~/research-storage-uct/Archiv_Tape/Liver-Semela/ /home/habi/P/Documents/Semela-Liver/Data/\n",
    "\n",
    "````\n",
    "(which is our standard `rsync` blurb for putting stuff *to* the archive, but without the `*.tif` files, so we get back all the relevant things :).\n",
    "\n",
    "We then delete all non-`ds17*`-folders with\n",
    "````bash\n",
    "find . -path './ds*' -prune -o -name '*' -delete -depth\n",
    "````\n",
    "(which does issue a warning because of `-depth`, but leaves us with only the `ds17_*`-folders :) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the folders that were used according to Mario.\n",
    "whichones = ['ctrl4', 'notch1_2', 'ctrl1', 'ctrl2', 'ctrl5', 'notch1_1', 'notch1_3', 'notch1_4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have *all* the necessary data (and some more), let's get to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make us a dataframe for saving all that we need\n",
    "Data = pandas.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get *all* log files\n",
    "Data['LogFile'] = [f for f in sorted(glob.glob(os.path.join(Root, '**', '*.log'), recursive=True))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all folders and generate sample, scan and experiment name\n",
    "Data['Folder'] = [os.path.dirname(f) for f in Data['LogFile']]\n",
    "Data['SampleName'] = [f[len(Root):].split(os.path.sep)[1].replace('ds17_','') for f in Data['Folder']]\n",
    "Data['Sample'] = [sn.replace('_rescan','').replace('_portal','').replace('_cava','') for sn in Data['SampleName']]\n",
    "Data['Scan'] = [f[len(Root):].split(os.path.sep)[2] for f in Data['Folder']]\n",
    "Data['Subfolder'] = [f[len(Root):].split(os.path.sep)[3] for f in Data['Folder']]\n",
    "Data['Experiment'] = [get_experiment(s) for s in Data['Sample']]\n",
    "Data['Vein'] = [get_vein(s) for s in Data['SampleName']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogFile       /home/habi/P/Documents/Semela-Liver/Data/Liver...\n",
      "Folder        /home/habi/P/Documents/Semela-Liver/Data/Liver...\n",
      "SampleName                                         ctrl3_portal\n",
      "Sample                                                    ctrl3\n",
      "Scan                                                   overview\n",
      "Subfolder                                                  proj\n",
      "Experiment                                              Control\n",
      "Vein                                                     Portal\n",
      "Name: 33, dtype: object\n",
      "--------------------------------------------------------------------------------\n",
      "/home/habi/P/Documents/Semela-Liver/Data/Liver-Semela/ds17_ctrl3_portal/overview/proj/ds17_ctrl3_portal.log\n",
      "/home/habi/P/Documents/Semela-Liver/Data/Liver-Semela/ds17_ctrl3_portal/overview/proj\n",
      "ctrl3_portal\n",
      "ctrl3\n",
      "overview\n",
      "proj\n",
      "Control\n",
      "Portal\n"
     ]
    }
   ],
   "source": [
    "# Check what we did there...\n",
    "print(Data.iloc[33])\n",
    "print(80*'-')\n",
    "for i in Data.iloc[33]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the voxelsize from each logfile\n",
    "Data['Voxelsize'] = [get_pixelsize(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One log file is empty, drop it\n",
    "# We cannot read a voxel size out of it...\n",
    "Data.drop(Data[Data['Voxelsize'].isna()].index, inplace=True)\n",
    "# We asked Mario et al. if they have a good copy of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scans were performed by ['haberthu']\n"
     ]
    }
   ],
   "source": [
    "Data['Operator'] = [get_operator(log) for log in Data['LogFile']]\n",
    "print('The scans were performed by %s' % Data.Operator.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folder</th>\n",
       "      <th>SampleName</th>\n",
       "      <th>Sample</th>\n",
       "      <th>Vein</th>\n",
       "      <th>Scan</th>\n",
       "      <th>Subfolder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/habi/P/Documents/Semela-Liver/Data/Liver...</td>\n",
       "      <td>ctrl1_portal</td>\n",
       "      <td>ctrl1</td>\n",
       "      <td>Portal</td>\n",
       "      <td>highresolution</td>\n",
       "      <td>proj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/habi/P/Documents/Semela-Liver/Data/Liver...</td>\n",
       "      <td>ctrl1_portal</td>\n",
       "      <td>ctrl1</td>\n",
       "      <td>Portal</td>\n",
       "      <td>highresolution</td>\n",
       "      <td>proj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/habi/P/Documents/Semela-Liver/Data/Liver...</td>\n",
       "      <td>ctrl1_portal</td>\n",
       "      <td>ctrl1</td>\n",
       "      <td>Portal</td>\n",
       "      <td>highresolution</td>\n",
       "      <td>proj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/habi/P/Documents/Semela-Liver/Data/Liver...</td>\n",
       "      <td>ctrl1_portal</td>\n",
       "      <td>ctrl1</td>\n",
       "      <td>Portal</td>\n",
       "      <td>highresolution</td>\n",
       "      <td>rec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/habi/P/Documents/Semela-Liver/Data/Liver...</td>\n",
       "      <td>ctrl1_portal</td>\n",
       "      <td>ctrl1</td>\n",
       "      <td>Portal</td>\n",
       "      <td>overview</td>\n",
       "      <td>proj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>/home/habi/P/Documents/Semela-Liver/Data/Liver...</td>\n",
       "      <td>notch1_4</td>\n",
       "      <td>notch1_4</td>\n",
       "      <td>None</td>\n",
       "      <td>rll_repeat_3um</td>\n",
       "      <td>rec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>/home/habi/P/Documents/Semela-Liver/Data/Liver...</td>\n",
       "      <td>notch1_4_rescan</td>\n",
       "      <td>notch1_4</td>\n",
       "      <td>None</td>\n",
       "      <td>highresolution</td>\n",
       "      <td>proj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>/home/habi/P/Documents/Semela-Liver/Data/Liver...</td>\n",
       "      <td>notch1_4_rescan</td>\n",
       "      <td>notch1_4</td>\n",
       "      <td>None</td>\n",
       "      <td>highresolution</td>\n",
       "      <td>proj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>/home/habi/P/Documents/Semela-Liver/Data/Liver...</td>\n",
       "      <td>notch1_4_rescan</td>\n",
       "      <td>notch1_4</td>\n",
       "      <td>None</td>\n",
       "      <td>highresolution</td>\n",
       "      <td>proj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>/home/habi/P/Documents/Semela-Liver/Data/Liver...</td>\n",
       "      <td>notch1_4_rescan</td>\n",
       "      <td>notch1_4</td>\n",
       "      <td>None</td>\n",
       "      <td>highresolution</td>\n",
       "      <td>rec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Folder       SampleName  \\\n",
       "0    /home/habi/P/Documents/Semela-Liver/Data/Liver...     ctrl1_portal   \n",
       "1    /home/habi/P/Documents/Semela-Liver/Data/Liver...     ctrl1_portal   \n",
       "2    /home/habi/P/Documents/Semela-Liver/Data/Liver...     ctrl1_portal   \n",
       "3    /home/habi/P/Documents/Semela-Liver/Data/Liver...     ctrl1_portal   \n",
       "4    /home/habi/P/Documents/Semela-Liver/Data/Liver...     ctrl1_portal   \n",
       "..                                                 ...              ...   \n",
       "131  /home/habi/P/Documents/Semela-Liver/Data/Liver...         notch1_4   \n",
       "132  /home/habi/P/Documents/Semela-Liver/Data/Liver...  notch1_4_rescan   \n",
       "133  /home/habi/P/Documents/Semela-Liver/Data/Liver...  notch1_4_rescan   \n",
       "134  /home/habi/P/Documents/Semela-Liver/Data/Liver...  notch1_4_rescan   \n",
       "135  /home/habi/P/Documents/Semela-Liver/Data/Liver...  notch1_4_rescan   \n",
       "\n",
       "       Sample    Vein            Scan Subfolder  \n",
       "0       ctrl1  Portal  highresolution      proj  \n",
       "1       ctrl1  Portal  highresolution      proj  \n",
       "2       ctrl1  Portal  highresolution      proj  \n",
       "3       ctrl1  Portal  highresolution       rec  \n",
       "4       ctrl1  Portal        overview      proj  \n",
       "..        ...     ...             ...       ...  \n",
       "131  notch1_4    None  rll_repeat_3um       rec  \n",
       "132  notch1_4    None  highresolution      proj  \n",
       "133  notch1_4    None  highresolution      proj  \n",
       "134  notch1_4    None  highresolution      proj  \n",
       "135  notch1_4    None  highresolution       rec  \n",
       "\n",
       "[135 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data[['Folder', 'SampleName', 'Sample', 'Vein', 'Scan', 'Subfolder']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctrl1\n",
      "ctrl2\n",
      "ctrl3\n",
      "ctrl4\n",
      "ctrl5\n",
      "ctrl6\n",
      "notch1_1\n",
      "notch1_2\n",
      "notch1_3\n",
      "notch1_4\n"
     ]
    }
   ],
   "source": [
    "# What samples do we have?\n",
    "for i in Data.Sample.unique():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ctrl1',\n",
       " 'ctrl2',\n",
       " 'ctrl4',\n",
       " 'ctrl5',\n",
       " 'notch1_1',\n",
       " 'notch1_2',\n",
       " 'notch1_3',\n",
       " 'notch1_4']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What Mario et al looked at\n",
    "sorted(whichones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ctrl3', 'ctrl6'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which ones are 'surplus'?\n",
    "set(Data.Sample.unique())-set(whichones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- For sample ctrl1 we have the data below ---------------\n",
      "   Sample    Vein           SampleName            Scan  Voxelsize\n",
      "0   ctrl1  Portal         ctrl1_portal  highresolution   5.000040\n",
      "1   ctrl1  Portal         ctrl1_portal  highresolution   5.000040\n",
      "2   ctrl1  Portal         ctrl1_portal  highresolution   5.000040\n",
      "3   ctrl1  Portal         ctrl1_portal  highresolution   5.000040\n",
      "4   ctrl1  Portal         ctrl1_portal        overview  21.754494\n",
      "5   ctrl1  Portal         ctrl1_portal        overview  21.101977\n",
      "6   ctrl1  Portal         ctrl1_portal        overview  21.754494\n",
      "8   ctrl1  Portal         ctrl1_portal             rll   3.000006\n",
      "9   ctrl1  Portal         ctrl1_portal             rll   3.000006\n",
      "10  ctrl1  Portal         ctrl1_portal             rll   3.000006\n",
      "11  ctrl1  Portal         ctrl1_portal             rll   3.000006\n",
      "12  ctrl1  Portal         ctrl1_portal         rll_5um   5.000024\n",
      "13  ctrl1  Portal         ctrl1_portal         rll_5um   5.000024\n",
      "14  ctrl1  Portal         ctrl1_portal         rll_5um   5.000024\n",
      "15  ctrl1  Portal         ctrl1_portal         rll_5um   5.000024\n",
      "16  ctrl1  Portal  ctrl1_portal_rescan  highresolution   5.000018\n",
      "17  ctrl1  Portal  ctrl1_portal_rescan  highresolution   5.000018\n",
      "18  ctrl1  Portal  ctrl1_portal_rescan  highresolution   5.000018\n",
      "19  ctrl1  Portal  ctrl1_portal_rescan  highresolution   5.000018\n",
      "--------------------------------------------------------------------------------\n",
      "--------------- For sample ctrl2 we have the data below ---------------\n",
      "   Sample    Vein           SampleName            Scan  Voxelsize\n",
      "20  ctrl2  Portal         ctrl2_portal        overview  21.754494\n",
      "21  ctrl2  Portal         ctrl2_portal        overview  21.754494\n",
      "22  ctrl2  Portal         ctrl2_portal        overview  21.754494\n",
      "23  ctrl2  Portal         ctrl2_portal        overview  21.754494\n",
      "24  ctrl2  Portal         ctrl2_portal         rll_5um   5.000336\n",
      "25  ctrl2  Portal         ctrl2_portal         rll_5um   5.000336\n",
      "26  ctrl2  Portal         ctrl2_portal         rll_5um   5.000336\n",
      "27  ctrl2  Portal         ctrl2_portal         rll_5um   5.000336\n",
      "28  ctrl2  Portal  ctrl2_portal_rescan  highresolution   5.000018\n",
      "29  ctrl2  Portal  ctrl2_portal_rescan  highresolution   5.000018\n",
      "30  ctrl2  Portal  ctrl2_portal_rescan  highresolution   5.000018\n",
      "31  ctrl2  Portal  ctrl2_portal_rescan  highresolution   5.000018\n",
      "32  ctrl2  Portal  ctrl2_portal_rescan  highresolution   5.000018\n",
      "--------------------------------------------------------------------------------\n",
      "--------------- For sample ctrl4 we have the data below ---------------\n",
      "   Sample  Vein  SampleName            Scan  Voxelsize\n",
      "37  ctrl4  Cava  ctrl4_cava  highresolution   5.000040\n",
      "38  ctrl4  Cava  ctrl4_cava  highresolution   5.000040\n",
      "39  ctrl4  Cava  ctrl4_cava  highresolution   5.000040\n",
      "40  ctrl4  Cava  ctrl4_cava  highresolution   5.000040\n",
      "41  ctrl4  Cava  ctrl4_cava        overview  21.754494\n",
      "42  ctrl4  Cava  ctrl4_cava        overview  21.754494\n",
      "43  ctrl4  Cava  ctrl4_cava        overview  21.754494\n",
      "44  ctrl4  Cava  ctrl4_cava        overview  21.754494\n",
      "--------------------------------------------------------------------------------\n",
      "--------------- For sample ctrl5 we have the data below ---------------\n",
      "   Sample  Vein         SampleName            Scan  Voxelsize\n",
      "45  ctrl5  Cava         ctrl5_cava  highresolution  19.910000\n",
      "46  ctrl5  Cava         ctrl5_cava  highresolution  19.910000\n",
      "47  ctrl5  Cava         ctrl5_cava  highresolution  19.910000\n",
      "48  ctrl5  Cava         ctrl5_cava  highresolution  19.910000\n",
      "49  ctrl5  Cava         ctrl5_cava  highresolution  19.909896\n",
      "50  ctrl5  Cava         ctrl5_cava  highresolution  19.909896\n",
      "51  ctrl5  Cava         ctrl5_cava  highresolution  19.909896\n",
      "52  ctrl5  Cava         ctrl5_cava  highresolution  19.910000\n",
      "53  ctrl5  Cava         ctrl5_cava  highresolution  19.909896\n",
      "54  ctrl5  Cava         ctrl5_cava        overview  21.799899\n",
      "55  ctrl5  Cava         ctrl5_cava        overview  21.799899\n",
      "56  ctrl5  Cava         ctrl5_cava        overview  21.799899\n",
      "57  ctrl5  Cava         ctrl5_cava        overview  21.799899\n",
      "58  ctrl5  Cava         ctrl5_cava         rll_5um   5.000336\n",
      "59  ctrl5  Cava         ctrl5_cava         rll_5um   5.000336\n",
      "60  ctrl5  Cava         ctrl5_cava         rll_5um   5.000336\n",
      "61  ctrl5  Cava         ctrl5_cava         rll_5um   5.000336\n",
      "62  ctrl5  Cava  ctrl5_cava_rescan  highresolution   5.000018\n",
      "63  ctrl5  Cava  ctrl5_cava_rescan  highresolution   5.000018\n",
      "64  ctrl5  Cava  ctrl5_cava_rescan  highresolution   5.000018\n",
      "65  ctrl5  Cava  ctrl5_cava_rescan  highresolution   5.000018\n",
      "--------------------------------------------------------------------------------\n",
      "--------------- For sample notch1_1 we have the data below ---------------\n",
      "      Sample  Vein       SampleName            Scan  Voxelsize\n",
      "70  notch1_1  None         notch1_1  highresolution   5.000040\n",
      "71  notch1_1  None         notch1_1  highresolution   5.000040\n",
      "72  notch1_1  None         notch1_1  highresolution   5.000040\n",
      "73  notch1_1  None         notch1_1  highresolution   5.000040\n",
      "74  notch1_1  None         notch1_1  highresolution   5.000040\n",
      "75  notch1_1  None         notch1_1        overview  15.000120\n",
      "76  notch1_1  None         notch1_1        overview  15.000120\n",
      "77  notch1_1  None         notch1_1        overview  15.000120\n",
      "78  notch1_1  None         notch1_1        overview  15.000120\n",
      "79  notch1_1  None         notch1_1        overview  15.000120\n",
      "80  notch1_1  None         notch1_1             rll   3.000006\n",
      "81  notch1_1  None         notch1_1             rll   3.000006\n",
      "82  notch1_1  None         notch1_1             rll   3.000006\n",
      "83  notch1_1  None         notch1_1             rll   3.000006\n",
      "84  notch1_1  None         notch1_1         rll_5um   5.001531\n",
      "85  notch1_1  None         notch1_1         rll_5um   5.001531\n",
      "86  notch1_1  None         notch1_1         rll_5um   5.001531\n",
      "87  notch1_1  None         notch1_1         rll_5um   5.001531\n",
      "88  notch1_1  None  notch1_1_rescan  highresolution   5.000018\n",
      "89  notch1_1  None  notch1_1_rescan  highresolution   5.000018\n",
      "90  notch1_1  None  notch1_1_rescan  highresolution   5.000018\n",
      "91  notch1_1  None  notch1_1_rescan  highresolution   5.000018\n",
      "--------------------------------------------------------------------------------\n",
      "--------------- For sample notch1_2 we have the data below ---------------\n",
      "      Sample  Vein SampleName      Scan  Voxelsize\n",
      "92  notch1_2  None   notch1_2  overview    5.00004\n",
      "93  notch1_2  None   notch1_2  overview    5.00004\n",
      "94  notch1_2  None   notch1_2  overview    5.00004\n",
      "95  notch1_2  None   notch1_2  overview    5.00004\n",
      "--------------------------------------------------------------------------------\n",
      "--------------- For sample notch1_3 we have the data below ---------------\n",
      "       Sample  Vein       SampleName            Scan  Voxelsize\n",
      "96   notch1_3  None         notch1_3        overview  15.000120\n",
      "97   notch1_3  None         notch1_3        overview  15.000120\n",
      "98   notch1_3  None         notch1_3        overview  15.000120\n",
      "99   notch1_3  None         notch1_3        overview  15.000120\n",
      "100  notch1_3  None         notch1_3         rll_5um   5.000336\n",
      "101  notch1_3  None         notch1_3         rll_5um   5.000336\n",
      "102  notch1_3  None         notch1_3         rll_5um   5.000336\n",
      "103  notch1_3  None         notch1_3         rll_5um   5.000336\n",
      "104  notch1_3  None  notch1_3_rescan  highresolution   5.000018\n",
      "105  notch1_3  None  notch1_3_rescan  highresolution   5.000018\n",
      "106  notch1_3  None  notch1_3_rescan  highresolution   5.000018\n",
      "107  notch1_3  None  notch1_3_rescan  highresolution   5.000018\n",
      "--------------------------------------------------------------------------------\n",
      "--------------- For sample notch1_4 we have the data below ---------------\n",
      "       Sample  Vein       SampleName            Scan  Voxelsize\n",
      "108  notch1_4  None         notch1_4  highresolution   5.000040\n",
      "109  notch1_4  None         notch1_4  highresolution   5.000040\n",
      "110  notch1_4  None         notch1_4  highresolution   5.000040\n",
      "111  notch1_4  None         notch1_4  highresolution   5.000040\n",
      "112  notch1_4  None         notch1_4        overview  15.000120\n",
      "113  notch1_4  None         notch1_4        overview  15.000120\n",
      "114  notch1_4  None         notch1_4        overview  15.000120\n",
      "115  notch1_4  None         notch1_4        overview  15.000120\n",
      "116  notch1_4  None         notch1_4        overview  15.000120\n",
      "117  notch1_4  None         notch1_4         rll_3um   3.000006\n",
      "118  notch1_4  None         notch1_4         rll_3um   3.000006\n",
      "119  notch1_4  None         notch1_4         rll_3um   3.000006\n",
      "120  notch1_4  None         notch1_4         rll_3um   3.000006\n",
      "121  notch1_4  None         notch1_4         rll_5um   5.001393\n",
      "122  notch1_4  None         notch1_4         rll_5um   5.001393\n",
      "123  notch1_4  None         notch1_4         rll_5um   5.001393\n",
      "124  notch1_4  None         notch1_4         rll_5um   5.001393\n",
      "125  notch1_4  None         notch1_4         rll_7um   6.999999\n",
      "126  notch1_4  None         notch1_4         rll_7um   6.999999\n",
      "127  notch1_4  None         notch1_4  rll_repeat_3um   3.000003\n",
      "128  notch1_4  None         notch1_4  rll_repeat_3um   3.000003\n",
      "129  notch1_4  None         notch1_4  rll_repeat_3um   3.000003\n",
      "130  notch1_4  None         notch1_4  rll_repeat_3um   3.000003\n",
      "131  notch1_4  None         notch1_4  rll_repeat_3um   3.000003\n",
      "132  notch1_4  None  notch1_4_rescan  highresolution   5.000018\n",
      "133  notch1_4  None  notch1_4_rescan  highresolution   5.000018\n",
      "134  notch1_4  None  notch1_4_rescan  highresolution   5.000018\n",
      "135  notch1_4  None  notch1_4_rescan  highresolution   5.000018\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Collate what Mario analyzed with what we scanned\n",
    "for wanted in sorted(whichones):\n",
    "    print(15 * '-', 'For sample %s we have the data below' % wanted, 15 * '-', )\n",
    "    print(Data[Data['Sample'].str.contains(wanted)][['Sample', 'Vein', 'SampleName', 'Scan', 'Voxelsize']])\n",
    "    print(80*'-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, from just looking throught the data based on the names that we have from Mario, it seems to me that they *only* looked at the 5 um scans.\n",
    "Let's `.drop()` all the other scans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of all non-5um scans\n",
    "Data.drop(Data[Data['Voxelsize']>5.5].index, inplace=True)\n",
    "Data.drop(Data[Data['Voxelsize']<4.5].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems that Mario et al. simply used the `highresolution` scans (either the scan or the `_rescan`).\n",
    "Now, let's get to work with extracting the data we need..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def scanner(logfile, verbose=False):\n",
    "    hardwareversion = []\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Scanner' in line:\n",
    "                if verbose:\n",
    "                    print(line)\n",
    "                # Sometimes it's SkyScan, sometimes Skyscan, so we have to regex it :)\n",
    "                machine = re.split('Sky.can', line)[1].strip()\n",
    "            if 'Hardware' in line:\n",
    "                if verbose:\n",
    "                    print(line)\n",
    "                hardwareversion = line.split('=')[1].strip()\n",
    "    if hardwareversion:\n",
    "        return('SkyScan %s (Version %s)' % (machine, hardwareversion))\n",
    "    else:\n",
    "        return('SkyScan ' + machine)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def controlsoftware(logfile, verbose=False):\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Software Ver' in line:\n",
    "                if verbose:\n",
    "                    print(line)\n",
    "                version = line.split('=')[1].strip()\n",
    "    return(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get parameters which we'll need for the paragraph\n",
    "Data['Scanner'] = [scanner(log) for log in Data['LogFile']]\n",
    "Data['ControlSoftware'] = [controlsoftware(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source(logfile, verbose=False):\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Source Ty' in line:\n",
    "                if verbose:\n",
    "                    print(line)\n",
    "                source = line.split('=')[1].strip()\n",
    "                if 'HAMAMA' in source:\n",
    "                    # We split the string at '_L' to separate HAMAMATSU_L118...\n",
    "                    # Afterwards we properly capitalize HAMAMATSU and\n",
    "                    # join the strings back with ' L' to get the beginning of the reference back\n",
    "                    source = ' L'.join([s.capitalize() for s in source.split('_L')])\n",
    "    return(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera(logfile, verbose=False):\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Camera T' in line or 'Camera=' in line:\n",
    "                if verbose:\n",
    "                    print(line)\n",
    "                cam = line.split('=')[1].strip().strip(' camera')\n",
    "    return(cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Source'] = [source(log) for log in Data['LogFile']]\n",
    "Data['Camera'] = [camera(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voltage(logfile, verbose=False):\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Voltage' in line:\n",
    "                if verbose:\n",
    "                    print(line)\n",
    "                V = float(line.split('=')[1])\n",
    "    return(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current(logfile, verbose=False):\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Source Current' in line:\n",
    "                if verbose:\n",
    "                    print(line)\n",
    "                A = float(line.split('=')[1])\n",
    "    return(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whichfilter(logfile, verbose=False):\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Filter=' in line:\n",
    "                if verbose:\n",
    "                    print(line)\n",
    "                fltr = line.split('=')[1].strip().replace('  ', ' ')\n",
    "                if fltr=='No Filter':\n",
    "                    fltr=False\n",
    "    return(fltr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Voltage'] = [voltage(log) for log in Data['LogFile']]\n",
    "Data['Current'] = [current(log) for log in Data['LogFile']]\n",
    "Data['Filter'] = [whichfilter(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camerasize(logfile, verbose=False):\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Columns' in line:\n",
    "                if verbose:\n",
    "                    print(line)\n",
    "                columns = int(line.split('=')[1])\n",
    "            if 'Rows' in line:\n",
    "                if verbose:\n",
    "                    print(line)\n",
    "                rows = int(line.split('=')[1])\n",
    "    return(columns, rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numproj(logfile, verbose=False):\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'f Files' in line:\n",
    "                if verbose:\n",
    "                    print(line)\n",
    "                numproj = int(line.split('=')[1])\n",
    "    return(numproj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotationstep(logfile, verbose=False):\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Rotation Step' in line:\n",
    "                if verbose:\n",
    "                    print(line)\n",
    "                rotstep = float(line.split('=')[1])\n",
    "    return(rotstep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['CamSize'] = [camerasize(log) for log in Data['LogFile']]\n",
    "Data['NumProj'] = [numproj(log) for log in Data['LogFile']]\n",
    "Data['RotationStep'] = [rotationstep(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacks(logfile, verbose=False):\n",
    "    with open(logfile, 'r') as f:\n",
    "        # If only one stack, then there's nothing in the log file\n",
    "        numstacks = 0\n",
    "        for line in f:\n",
    "            if 'of conn' in line:\n",
    "                if verbose:\n",
    "                    print(line)\n",
    "                # The 'Sub-scan scan length' is listed in the log file\n",
    "                # We simply select the last one, and add 1, since Bruker also starts to count at zero\n",
    "                numstacks = int(line.split('=')[1])\n",
    "    return(numstacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlapscan(logfile, verbose=False):\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Horizontal Off' in line:\n",
    "                if verbose:\n",
    "                    print(line)\n",
    "                wide = int(line.split('=')[1])\n",
    "                if wide == 1:\n",
    "                    wide=False\n",
    "    return(wide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threesixtyscan(logfile, verbose=False):\n",
    "    threesixty = False\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if '0 Rotation' in line:\n",
    "                if verbose:\n",
    "                    print(line)\n",
    "                threesixty = line.split('=')[1].strip()\n",
    "                if threesixty == 'YES':\n",
    "                    threesixty = True\n",
    "    return(threesixty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Stacks'] = [stacks(log) for log in Data['LogFile']]\n",
    "Data['Wide'] = [overlapscan(log) for log in Data.LogFile]\n",
    "Data['ThreeSixty'] = [threesixtyscan(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exposure(logfile, verbose=False):\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Exposure' in line:\n",
    "                if verbose:\n",
    "                    print(line)\n",
    "                exp = int(line.split('=')[1])\n",
    "    return(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averaging(logfile, verbose=False):\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Avera' in line:\n",
    "                if verbose:\n",
    "                    print(line)\n",
    "                details = line.split('=')[1]\n",
    "                if 'ON' in details:\n",
    "                    # https://stackoverflow.com/a/4894156/323100\n",
    "                    avg = int(details[details.find(\"(\")+1:details.find(\")\")])\n",
    "                else:\n",
    "                    avg=False\n",
    "    return(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Exposure'] = [exposure(log) for log in Data['LogFile']]\n",
    "Data['Averaging'] = [averaging(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ringremoval(logfile, verbose=False):\n",
    "    ring = numpy.nan\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Ring' in line:\n",
    "                if verbose:\n",
    "                    print(line)\n",
    "                ring = int(line.split('=')[1].strip())\n",
    "    return(ring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beamhardening(logfile, verbose=False):\n",
    "    bh = numpy.nan\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'ardeni' in line:\n",
    "                if verbose:\n",
    "                    print(line)\n",
    "                bh = int(line.split('=')[1].strip())\n",
    "    return(bh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reconstruction_grayvalue(logfile):\n",
    "    grayvalue = None\n",
    "    \"\"\"How did we map the brightness of the reconstructions?\"\"\"\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Maximum for' in line:\n",
    "                grayvalue = float(line.split('=')[1])\n",
    "    return(grayvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['RingRemoval'] = [ringremoval(log) for log in Data['LogFile']]\n",
    "Data['Beamhardening'] = [beamhardening(log) for log in Data['LogFile']]\n",
    "Data['GrayValueMax'] = [get_reconstruction_grayvalue(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def duration(logfile, verbose=False):\n",
    "    '''Returns scantime in *seconds*'''\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Scan duration' in line:\n",
    "                if verbose:\n",
    "                    print(line)\n",
    "                duration = line.split('=')[1].strip()\n",
    "    # Sometimes it's '00:24:26', sometimes '0h:52m:53s' :-/\n",
    "    if 'h' in duration:\n",
    "        scantime = datetime.datetime.strptime(duration, '%Hh:%Mm:%Ss')\n",
    "    else:\n",
    "        scantime = datetime.datetime.strptime(duration, '%H:%M:%S')\n",
    "    return((scantime-datetime.datetime(1900,1,1)).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_scantime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_834635/138236749.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Scan time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_scantime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LogFile'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Scan time total'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mst\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstk\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Duration'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Stacks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_834635/138236749.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Scan time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_scantime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LogFile'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Scan time total'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mst\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstk\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Duration'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Stacks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_scantime' is not defined"
     ]
    }
   ],
   "source": [
    "Data['Scan time'] = [get_scantime(log) for log in Data['LogFile']]\n",
    "Data['Scan time total'] = [ st * stk  for st, stk in zip(Data['Duration'], Data['Stacks'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nreconversion(logfile, verbose=False):\n",
    "    Program = numpy.nan\n",
    "    Version = numpy.nan\n",
    "    with open(logfile, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'Reconstruction Program' in line:\n",
    "                if verbose:\n",
    "                    print(line)\n",
    "                Program = line.split('=')[1].strip()\n",
    "            if 'Program Version' in line:\n",
    "                if verbose:\n",
    "                    print(line)\n",
    "                Version = line.split('sion:')[1].strip()\n",
    "    return(Program, Version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['NRecon'] = [nreconversion(log) for log in Data['LogFile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.00004 , 5.000024, 5.000018, 5.000336, 5.001531, 5.001393])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.Voxelsize.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We scanned all datasets with equal voxel size, namely 5.0 um.\n"
     ]
    }
   ],
   "source": [
    "# Check voxel sizes (*rounded* to two after-comma values)\n",
    "# If different, spit out which values\n",
    "roundto = 2\n",
    "if len(Data['Voxelsize'].round(roundto).unique()) > 1:\n",
    "    print('We scanned all datasets with %s different voxel sizes' % len(Data['Voxelsize'].round(roundto).unique()))\n",
    "    for vs in sorted(Data['Voxelsize'].round(roundto).unique()):\n",
    "        print('-', vs, 'um for ', end='')\n",
    "        for c, row in Data.iterrows():\n",
    "            if float(vs) == round(row['Voxelsize'], roundto):\n",
    "                print(os.path.join(row['Sample'], row['Scan']), end=', ')\n",
    "        print('')\n",
    "else:\n",
    "    print('We scanned all datasets with equal voxel size, namely %s um.' % float(Data['Voxelsize'].round(roundto).unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Scan time total'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3621\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3622\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Scan time total'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_834635/3868905729.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get an overview over the total scan time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Nice output based on https://stackoverflow.com/a/8907407/323100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtotal_seconds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Scan time total'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mhours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremainder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdivmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mminutes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseconds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdivmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremainder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3504\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3505\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3506\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3507\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3622\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3623\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3624\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3625\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Scan time total'"
     ]
    }
   ],
   "source": [
    "# Get an overview over the total scan time\n",
    "# Nice output based on https://stackoverflow.com/a/8907407/323100\n",
    "total_seconds = int(Data['Scan time total'].sum().total_seconds())\n",
    "hours, remainder = divmod(total_seconds,60*60)\n",
    "minutes, seconds = divmod(remainder,60)\n",
    "print('In total, we scanned for %s hours and %s minutes)' % (hours, minutes))\n",
    "for machine in Data['Scanner'].unique():\n",
    "    total_seconds = int(Data[Data['Scanner'] == machine]['Scan time total'].sum().total_seconds())\n",
    "    hours, remainder = divmod(total_seconds,60*60)\n",
    "    minutes, seconds = divmod(remainder,60)\n",
    "    print('\\t - Of these, we scanned %s hours and %s minutes on the %s,'\n",
    "          'for %s scans' % (hours,\n",
    "                            minutes,\n",
    "                            machine,\n",
    "                            len(Data[Data['Scanner'] == machine])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.to_excel('Details.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.to_excel(os.path.join(Root,'Details.xlsx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the data, but some of it is hidden in the `proj` and some of it in the `rec` log files..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My microct blurb from http://simp.ly/publish/NBhZhH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the 70 log files in /home/habi/P/Documents/Semela-Liver/Data/Liver-Semela\n"
     ]
    }
   ],
   "source": [
    "print('Based on the %s log files in %s' % (len(Data), Root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SkyScan 1272'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" OR \".join(str(value) for value in Data.Scanner.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After $PREPARATION, the 70 samples were imaged on a Bruker SkyScan 1272 high-resolution microtomography machine (Control software version 1.1.9 OR 1.1.19, Bruker microCT, Kontich, Belgium).\n"
     ]
    }
   ],
   "source": [
    "print('After $PREPARATION, the',\n",
    "      len(Data),\n",
    "      'samples were imaged on a Bruker',\n",
    "      \" OR \".join(str(value) for value in Data.Scanner.unique()),\n",
    "      'high-resolution microtomography machine (Control software version',\n",
    "      \" OR \".join(str(value) for value in Data.ControlSoftware.unique()) + \n",
    "      ', Bruker microCT, Kontich, Belgium).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The machine is equipped with a Hamamatsu L11871_20 X-ray source and a XIMEA xiRAY16 camera.\n"
     ]
    }
   ],
   "source": [
    "print('The machine is equipped with a',\n",
    "      \" OR \".join(str(value) for value in Data.Source.unique()),\n",
    "      'X-ray source and a',\n",
    "      \" OR \".join(str(value) for value in Data.Camera.unique()),\n",
    "      'camera.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if len(Data.Scanner.unique()) > 1:\n",
    "#     print('more')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The X-ray source was set to a tube voltage of 100.0 kV and a tube current of 100.0 µA, the x-ray spectrum was filtered by Cu 0.11mm prior to incidence onto the sample.\n"
     ]
    }
   ],
   "source": [
    "print('The X-ray source was set to a tube voltage of', \n",
    "      \" OR \".join(str(value) for value in Data.Voltage.unique()),\n",
    "      'kV and a tube current of',\n",
    "      \" OR \".join(str(value) for value in Data.Current.unique()),\n",
    "      'µA, the x-ray spectrum was', end=' ')\n",
    "if Data.Filter.unique():\n",
    "    print('filtered by', \" OR \".join(str(value) for value in Data.Filter.unique()), end=' ')\n",
    "else:\n",
    "    print('not filtered', end=' ')\n",
    "print('prior to incidence onto the sample.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each sample, we recorded a set of 2 or 3 stacked scans overlapping the sample height, each stack was recorded with 1895 or 962 or 974 projections of 4904 2452 4664 x 3280 1640 1638 pixels (False or 2 projections stitched laterally) at every 0.1 or 0.2° over a 360° sample rotation.\n"
     ]
    }
   ],
   "source": [
    "print('For each sample, we recorded a set of', end=' ')\n",
    "if Data.Filter.unique().tolist():   \n",
    "    print(\" or \".join(str(value) for value in Data.Stacks.unique()),\n",
    "          'stacked scans overlapping the sample height, each stack was recorded with', end=' ')\n",
    "print(\" or \".join(str(value) for value in Data.NumProj.unique()), 'projections of', end=' ')\n",
    "for cs in Data.CamSize.unique():\n",
    "    print(cs[0], end=' ')\n",
    "print('x', end=' ')\n",
    "for cs in Data.CamSize.unique():\n",
    "    print(cs[1], end=' ')\n",
    "print('pixels', end=' ')\n",
    "if Data.Wide.unique().tolist():\n",
    "    print('(' + \" or \".join(str(value) for value in Data.Wide.unique()), 'projections stitched laterally)', end=' ')\n",
    "print('at every',\n",
    "       str(\" or \".join(str(value) for value in Data.RotationStep.unique())) + '° over a ', end='')\n",
    "if Data.ThreeSixty.unique().tolist():\n",
    "     print('360°', end=' ')\n",
    "else:\n",
    "    print('180°', end=' ')\n",
    "print('sample rotation.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NO']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.ThreeSixty.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5946.042857142857"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.Exposure.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every single projection was exposed for 5391 or 3923 or 4400 or 8866 ms, 3 projections were averaged to greatly reduce image noise.\n"
     ]
    }
   ],
   "source": [
    "print('Every single projection was exposed for',\n",
    "      \" or \".join(str(value) for value in Data.Exposure.unique()),\n",
    "      'ms,',\n",
    "      \" or \".join(str(value) for value in Data.Averaging.unique()),\n",
    "      'projections were averaged to greatly reduce image noise.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "log=Data['LogFile'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of connected scans=2\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacks(log, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This resulted in a scan time of approximately "
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'timeformat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_834635/812052419.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3600\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Scan took hours\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     print(timeformat(datetime.timedelta(seconds=duration(log)),\n\u001b[0m\u001b[1;32m      5\u001b[0m                      '{hours} hours and {minutes} minutes'), end=' ')\n\u001b[1;32m      6\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'timeformat' is not defined"
     ]
    }
   ],
   "source": [
    "print('This resulted in a scan time of approximately ', end='')\n",
    "if duration(log)/3600 > 1:\n",
    "    # Scan took hours\n",
    "    print(timeformat(datetime.timedelta(seconds=duration(log)),\n",
    "                     '{hours} hours and {minutes} minutes'), end=' ')\n",
    "else:\n",
    "    print(timeformat(datetime.timedelta(seconds=duration(log)),\n",
    "                     '{minutes} minutes'), end=' ')\n",
    "if not stacks(log) == 1:\n",
    "    print('per stack and about',\n",
    "          timeformat(stacks(log) * datetime.timedelta(seconds=duration(log)),\n",
    "                     '{hours} hours and {minutes} minutes'), end=' ')\n",
    "print('per sample', end='')\n",
    "if stacks(log) == 1:\n",
    "    print('.')\n",
    "else:\n",
    "    print(' (with', stacks(log), 'stacks).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2.0714285714285716)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Data.Scan.unique()), Data.Stacks.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, we scanned 145 stacks.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Duration'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_834635/2415101806.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'In total, we scanned'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stacks.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m print('Each stack took approximately',\n\u001b[0;32m----> 3\u001b[0;31m       \u001b[0mData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDuration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m       'minutes (' + str(datetime.timedelta(seconds=Data.Duration.mean())) + ')')\n\u001b[1;32m      5\u001b[0m print('In total, we thus scanned for about', \n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5581\u001b[0m         ):\n\u001b[1;32m   5582\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5583\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5585\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Duration'"
     ]
    }
   ],
   "source": [
    "print('In total, we scanned', Data.Stacks.sum(), 'stacks.')\n",
    "print('Each stack took approximately',\n",
    "      Data.Duration.mean() // 60,\n",
    "      'minutes (' + str(datetime.timedelta(seconds=Data.Duration.mean())) + ')')\n",
    "print('In total, we thus scanned for about', \n",
    "      timeformat(Data.Stacks.sum() *\n",
    "                 datetime.timedelta(seconds=Data.Duration.mean()),\n",
    "                 '{days} days, {hours} hours and {minutes} minutes.'))\n",
    "hourlyrate = 125\n",
    "print('At the MIC rate of %s CHF/h, this would have cost %s CHF' % (\n",
    "    hourlyrate,\n",
    "    int(round(Data.Stacks.sum() * Data.Duration.mean() / 60 / 60 * hourlyrate))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, we scanned 3 samples at 2.0714285714285716 stacks on average\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Duration'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_834635/1956371857.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'In total, we scanned %s samples at %s stacks on average'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m print('Each stack took approximately',\n\u001b[0;32m----> 3\u001b[0;31m       \u001b[0mData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDuration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m       'minutes (' + str(datetime.timedelta(seconds=Data.Duration.mean())) + ')')\n\u001b[1;32m      5\u001b[0m print('In total, we thus scanned for about', \n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5581\u001b[0m         ):\n\u001b[1;32m   5582\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5583\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5585\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Duration'"
     ]
    }
   ],
   "source": [
    "print('In total, we scanned %s samples at %s stacks on average' % (len(Data.Scan.unique()), Data.Stacks.mean()))\n",
    "print('Each stack took approximately',\n",
    "      Data.Duration.mean() // 60,\n",
    "      'minutes (' + str(datetime.timedelta(seconds=Data.Duration.mean())) + ')')\n",
    "print('In total, we thus scanned for about', \n",
    "      timeformat(len(Data.Scan.unique()) * Data.Stacks.mean() *\n",
    "                 datetime.timedelta(seconds=Data.Duration.mean()),\n",
    "                 '{days} days, {hours} hours and {minutes} minutes.'))\n",
    "print('At the MIC rate, this would have cost',\n",
    "      int(round(len(Data.Scan.unique()) * Data.Stacks.mean() * Data.Duration.mean() / 60 / 60 * 75)),\n",
    "      'CHF.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.NRecon.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The projection images were then subsequently reconstructed into a 3D stack',\n",
    "      'of images with',\n",
    "      Data.Version.unique()[0][0],\n",
    "      '(Version',\n",
    "      version(log)[1] + ', Bruker microCT, Kontich Belgium)', end=' ')\n",
    "if ringremoval(log):\n",
    "    print('using a ring artifact correction of',\n",
    "          ringremoval(log), end='')\n",
    "if beamhardening(log):\n",
    "    print(' and a beam hardening correction of',\n",
    "          beamhardening(log),\n",
    "          '%.')\n",
    "else:\n",
    "    print('.')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The whole process resulted in datasets with an isometric voxel size of',\n",
    "      \" or \".join(str(value) for value in Data.Voxelsize_rounded.unique()),\n",
    "      'µm.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fulllog(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.Voxelsize.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data[['Scan', 'Beamhardening', 'RingRemoval']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
